# Adapted Datasets

## Overview
This section introduces the list of datasets adapted by `AGI-Eval`.

Each dataset provides the framework's default evaluation configuration, which can be used to quickly start evaluation tasks based on this configuration.

## Dataset List

| Dataset Name | Resource URL | Evaluation Config |
| --- | --- | --- |
| AIME_2024 | [AIME_2024](https://huggingface.co/datasets/HuggingFaceH4/aime_2024) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/AIME_2024) |
| AIME_2025 | [AIME_2025](https://huggingface.co/datasets/opencompass/AIME2025) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/AIME_2025) |
| BBEH | [BBEH](https://huggingface.co/datasets/BBEH/bbeh) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/BBEH) |
| BBH-Cot-3Shot | [BBH-Cot-3Shot](https://huggingface.co/datasets/lukaemon/bbh) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/BBH-Cot-3Shot) |
| BeyondAIME | [BeyondAIME](https://huggingface.co/datasets/ByteDance-Seed/BeyondAIME) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/BeyondAIME) |
| CEval | [CEval](https://huggingface.co/datasets/ceval/ceval-exam) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/CEval) |
| CMMLU | [CMMLU](https://huggingface.co/datasets/lmlmcat/cmmlu) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/CMMLU) |
| DROP | [DROP](https://huggingface.co/datasets/ucinlp/drop) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/DROP) |
| GPQA | [GPQA](https://huggingface.co/datasets/Idavidrein/gpqa) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/GPQA) |
| GSM8K | [GSM8K](https://huggingface.co/datasets/openai/gsm8k) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/GSM8K) |
| IFEval | [IFEval](https://huggingface.co/datasets/google/IFEval) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/IFEval) |
| MATH | [MATH](https://huggingface.co/datasets/hendrycks/competition_math) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/MATH) |
| MATH-500 | [MATH-500](https://huggingface.co/datasets/HuggingFaceH4/MATH-500) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/MATH-500) |
| MGSM | [MGSM](https://huggingface.co/datasets/juletxara/mgsm) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/MGSM) |
| MMLU | [MMLU](https://huggingface.co/datasets/cais/mmlu) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/MMLU) |
| MMLU-Pro | [MMLU-Pro](https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/MMLU-Pro) |
| MMLU-Redux | [MMLU-Redux](https://huggingface.co/datasets/edinburgh-dawg/mmlu-redux) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/MMLU-Redux) |
| MMMLU | [MMMLU](https://huggingface.co/datasets/openai/MMMLU) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/MMMLU) |
| OlympiadBench | [OlympiadBench](https://huggingface.co/datasets/Hothan/OlympiadBench) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/OlympiadBench) |
| SimpleQA | [SimpleQA](https://huggingface.co/datasets/basicv8vc/SimpleQA) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/SimpleQA) |
| SuperGPQA | [SuperGPQA](https://huggingface.co/datasets/m-a-p/SuperGPQA) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/SuperGPQA) |
| mIFEval | [mIFEval](https://huggingface.co/datasets/Qwen/P-MMEval) | [config](https://github.com/AGI-Eval-Official/agi-eval-benchmarks/tree/master/mIFEval) |
